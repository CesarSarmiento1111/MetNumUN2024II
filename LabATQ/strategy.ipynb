{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CesarSarmiento1111/MetNumUN2024II/blob/main/LabATQ/strategy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40uJyzzSKf-E"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "import xarray as xr  # xarray for data manipulation\n",
        "\n",
        "import qnt.data as qndata     # functions for loading data\n",
        "import qnt.backtester as qnbt # built-in backtester\n",
        "import qnt.ta as qnta         # technical analysis library\n",
        "import qnt.stats as qnstats   # statistical functions\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.seterr(divide = \"ignore\")\n",
        "\n",
        "from qnt.ta.macd import macd\n",
        "from qnt.ta.rsi  import rsi\n",
        "from qnt.ta.stochastic import stochastic_k, stochastic, slow_stochastic\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2NJR_rRKf-G"
      },
      "outputs": [],
      "source": [
        "stock_data = qndata.stocks_load_spx_data(min_date='2005-06-01')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvJ16zUaKf-G"
      },
      "outputs": [],
      "source": [
        "def get_features(data):\n",
        "    \"\"\"Builds the features used for learning:\n",
        "       * a trend indicator;\n",
        "       * the moving average convergence divergence;\n",
        "       * a volatility measure;\n",
        "       * the stochastic oscillator;\n",
        "       * the relative strength index;\n",
        "       * the logarithm of the closing price;\n",
        "       * Trix indicator.\n",
        "       * Average True Range (ATR);\n",
        "       * On-Balance Volume (OBV).\n",
        "       These features can be modified and new ones can be added easily.\n",
        "    \"\"\"\n",
        "\n",
        "    # trend:\n",
        "    #trend = qnta.roc(qnta.lwma(data.sel(field=\"close\"), 60), 1)\n",
        "\n",
        "    # Liquidity filter (1.0 for liquid assets, 0.0 for non-liquid assets):\n",
        "    liq = data.sel(field=\"is_liquid\").ffill(\"time\").bfill(\"time\").fillna(0)\n",
        "\n",
        "    # moving average convergence divergence (MACD):\n",
        "    macd = qnta.macd(data.sel(field=\"close\"))\n",
        "    macd2_line, macd2_signal, macd2_hist = qnta.macd(data, 12, 26, 9)\n",
        "\n",
        "    # volatility:\n",
        "    volatility = qnta.tr(data.sel(field=\"high\"), data.sel(field=\"low\"), data.sel(field=\"close\"))\n",
        "    volatility = volatility / data.sel(field=\"close\")\n",
        "    volatility = qnta.lwma(volatility, 14)\n",
        "\n",
        "    # the stochastic oscillator:\n",
        "    #k, d = qnta.stochastic(data.sel(field=\"high\"), data.sel(field=\"low\"), data.sel(field=\"close\"), 14)\n",
        "\n",
        "    # the relative strength index:\n",
        "    rsi = qnta.rsi(data.sel(field=\"close\"))\n",
        "\n",
        "    # the logarithm of the closing price:\n",
        "    #price = data.sel(field=\"close\").ffill(\"time\").bfill(\"time\").fillna(0)  # fill NaN\n",
        "    #price = np.log(price)\n",
        "\n",
        "    # new feature: Trix (TRIX)\n",
        "    trix = qnta.trix(data.sel(field=\"close\"), 15)  # Using a period of 15 (can be adjusted)\n",
        "\n",
        "    # new feature: Average True Range (ATR)\n",
        "    atr = qnta.atr(data.sel(field=\"high\"), data.sel(field=\"low\"), data.sel(field=\"close\"), 14).expand_dims(field=[\"atr\"])\n",
        "\n",
        "    obv = qnta.obv(data.sel(field=\"close\"), data.sel(field=\"vol\")).expand_dims(field=[\"obv\"])\n",
        "\n",
        "\n",
        "    # combine the features:\n",
        "    result = xr.concat(\n",
        "        [macd2_signal.sel(field=\"close\"), volatility, rsi, trix, atr, obv],\n",
        "        pd.Index(\n",
        "            [\"macd\", \"volatility\", \"rsi\", \"trix\", \"atr\", \"obv\"],\n",
        "            name=\"field\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Expand liquidity to match dimensions of result\n",
        "    liq_expanded = liq.expand_dims(field=result.field)  # Match the \"field\" dimension\n",
        "\n",
        "    # Apply liquidity filter (assets with liq == 0 will be excluded)\n",
        "    result = result.where(liq_expanded > 0.5, drop=True)\n",
        "\n",
        "\n",
        "    return result.transpose(\"time\", \"field\", \"asset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4Znw1MMKf-H"
      },
      "outputs": [],
      "source": [
        "# displaying the features:\n",
        "my_features = get_features(stock_data)\n",
        "display(my_features.sel(field=\"trix\").to_pandas())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYKUaxWNKf-I"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "\n",
        "def get_target_classes(data):\n",
        "    \"\"\" Target classes for predicting if price goes up, down, or stays the same.\"\"\"\n",
        "\n",
        "    price_current = data.sel(field=\"close\")\n",
        "    price_future = qnta.shift(price_current, -1).fillna(price_current)  # Manejo de NaNs\n",
        "\n",
        "    class_buy = 1    # prices goes up\n",
        "    class_hold = 0   # prices stay the same\n",
        "    class_sell = -1  # prices go down\n",
        "\n",
        "    epsilon = 0.1  # Ajusta el umbral según la escala de precios\n",
        "\n",
        "    # Alinear dimensiones antes de clasificar\n",
        "    price_current, price_future = xr.align(price_current, price_future, join=\"inner\")\n",
        "\n",
        "    # Clasificación basada en comparación con epsilon\n",
        "    target_classes = xr.where(\n",
        "        price_future > price_current + epsilon, class_buy,\n",
        "        xr.where(\n",
        "            price_future < price_current - epsilon, class_sell,\n",
        "            class_hold\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return target_classes\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDCTN1u2Kf-I"
      },
      "outputs": [],
      "source": [
        "def get_target_classes(data):\n",
        "    \"\"\"Target classes for predicting if price goes up, down, or stays the same.\"\"\"\n",
        "\n",
        "    # Calcular la variación porcentual diaria\n",
        "    price_change_ratio = qnta.change(data.sel(field=\"close\")) / data.sel(field=\"close\")\n",
        "    future_price_change_ratio = price_change_ratio.shift(time=-1).fillna(0)  # Manejo de NaNs\n",
        "\n",
        "    # Definir clases\n",
        "    class_positive = 1  # Price goes up more than move\n",
        "    class_neutral = 0   # Price does not move more than move\n",
        "    class_negative = -1 # Price goes down more than move\n",
        "\n",
        "    # Umbral de movimiento (ajustar según sea necesario)\n",
        "    move = 0.02  # 1%\n",
        "\n",
        "    # Clasificar los rendimientos futuros\n",
        "    target_price = xr.where(\n",
        "        future_price_change_ratio < -move, class_negative, future_price_change_ratio\n",
        "    )\n",
        "    target_price = xr.where(\n",
        "        future_price_change_ratio > move, class_positive, target_price\n",
        "    )\n",
        "    target_price = xr.where(abs(future_price_change_ratio) <= move, class_neutral, target_price)\n",
        "\n",
        "    return target_price\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80N9wd3lKf-J"
      },
      "outputs": [],
      "source": [
        "def get_target_classes(data):\n",
        "    \"\"\" Target classes for predicting if price goes up or down.\"\"\"\n",
        "\n",
        "    price_current = data.sel(field=\"close\")\n",
        "    price_future  = qnta.shift(price_current, -1)\n",
        "\n",
        "    class_positive = 1 # prices goes up\n",
        "    class_negative = 0 # price goes down\n",
        "\n",
        "    target_price_up = xr.where(price_future > price_current, class_positive, class_negative)\n",
        "\n",
        "    return target_price_up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWnUMuYqKf-J"
      },
      "outputs": [],
      "source": [
        "def get_target_classes(data):\n",
        "    \"\"\"Target classes for predicting if price goes down or stays the same/up.\"\"\"\n",
        "\n",
        "    price_current = data.sel(field=\"close\")\n",
        "    price_future  = qnta.shift(price_current, -1)\n",
        "\n",
        "    class_down  = -1  # price goes down\n",
        "    class_same  = 0   # price stays the same or goes up\n",
        "\n",
        "    target_price_up = xr.where(price_future < price_current, class_down, class_same)\n",
        "\n",
        "    return target_price_up\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABnG5CoOKf-J"
      },
      "outputs": [],
      "source": [
        "# displaying the target classes:\n",
        "my_targetclass = get_target_classes(stock_data)\n",
        "display(my_targetclass.to_pandas())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a64p5mVHKf-K"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    \"\"\"Constructor para el modelo ML: HistGradientBoostingClassifier.\"\"\"\n",
        "    model = HistGradientBoostingClassifier()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDzvMNQIKf-K"
      },
      "outputs": [],
      "source": [
        "# Create and train the models working on an asset-by-asset basis.\n",
        "\n",
        "asset_name_all = stock_data.coords[\"asset\"].values\n",
        "\n",
        "target_assets = set(my_targetclass.coords['asset'].values)\n",
        "feature_assets = set(my_features.coords['asset'].values)\n",
        "common_assets = target_assets.intersection(feature_assets)\n",
        "\n",
        "models = dict()\n",
        "\n",
        "for asset_name in common_assets:\n",
        "        target_cur = my_targetclass.sel(asset=asset_name).dropna(\"time\", \"any\")\n",
        "        features_cur = my_features.sel(asset=asset_name).dropna(\"time\", \"any\")\n",
        "\n",
        "        # align features and targets:\n",
        "        target_for_learn_df, feature_for_learn_df = xr.align(target_cur, features_cur, join=\"inner\")\n",
        "\n",
        "        if len(features_cur.time) < 10:\n",
        "            # not enough points for training\n",
        "                continue\n",
        "            # HistGradientBoostingClassifier requires targets as 1D arrays\n",
        "        target_for_learn = target_for_learn_df.values.ravel()\n",
        "        features_for_learn = feature_for_learn_df.values\n",
        "\n",
        "        model = get_model()\n",
        "\n",
        "        try:\n",
        "            model.fit(feature_for_learn_df.values, target_for_learn_df)\n",
        "            models[asset_name] = model\n",
        "\n",
        "        except:\n",
        "            logging.exception(\"model training failed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoFpKGLsKf-K"
      },
      "outputs": [],
      "source": [
        "# Prediction and generating output weights:\n",
        "weights = xr.zeros_like(stock_data.sel(field=\"close\"))\n",
        "\n",
        "for asset_name in asset_name_all:\n",
        "    if asset_name in models:\n",
        "        model = models[asset_name]\n",
        "        features_all = my_features\n",
        "        features_cur = features_all.sel(asset=asset_name).dropna(\"time\", \"any\")\n",
        "        if len(features_cur.time) < 1:\n",
        "            continue\n",
        "        try:\n",
        "            # HistGradientBoostingClassifier outputs probabilities, so we take class probabilities for class 1\n",
        "            probs = model.predict_proba(features_cur.values)[:, 1]\n",
        "            weights.loc[dict(asset=asset_name, time=features_cur.time.values)] = probs\n",
        "        except KeyboardInterrupt as e:\n",
        "            raise e\n",
        "        except:\n",
        "            logging.exception(\"model prediction failed\")\n",
        "\n",
        "print(weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExdTiUlVKf-K"
      },
      "outputs": [],
      "source": [
        "def get_sharpe(stock_data, weights):\n",
        "    \"\"\"Calculates the Sharpe ratio\"\"\"\n",
        "    rr = qnstats.calc_relative_return(stock_data, weights)\n",
        "    sharpe = qnstats.calc_sharpe_ratio_annualized(rr).values[-1]\n",
        "    return sharpe\n",
        "\n",
        "sharpe = get_sharpe(stock_data, weights)\n",
        "sharpe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c0X3VzYKf-K"
      },
      "source": [
        "The sharpe ratio using the method above follows from **forward looking**. Predictions for (let us say) 2017 know about the relation between features and targets in 2020. Let us visualize the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X97kOV3eKf-L"
      },
      "outputs": [],
      "source": [
        "import qnt.graph as qngraph\n",
        "\n",
        "statistics = qnstats.calc_stat(stock_data, weights)\n",
        "\n",
        "display(statistics.to_pandas().tail())\n",
        "\n",
        "performance = statistics.to_pandas()[\"equity\"]\n",
        "qngraph.make_plot_filled(performance.index, performance, name=\"PnL (Equity)\", type=\"log\")\n",
        "\n",
        "display(statistics[-1:].sel(field = [\"sharpe_ratio\"]).transpose().to_pandas())\n",
        "\n",
        "# check for correlations with existing strategies:\n",
        "qnstats.print_correlation(weights,stock_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIMeg04oKf-M"
      },
      "outputs": [],
      "source": [
        "\"\"\"R2 (coefficient of determination) regression score function.\"\"\"\n",
        "r2_score(my_targetclass, weights, multioutput=\"variance_weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7BkeVbmKf-M"
      },
      "outputs": [],
      "source": [
        "\"\"\"The explained variance score explains the dispersion of errors of a given dataset\"\"\"\n",
        "explained_variance_score(my_targetclass, weights, multioutput=\"uniform_average\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_ttbY3qKf-M"
      },
      "outputs": [],
      "source": [
        "\"\"\"The explained variance score explains the dispersion of errors of a given dataset\"\"\"\n",
        "mean_absolute_error(my_targetclass, weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvQbj4eqKf-M"
      },
      "source": [
        "Let us now use the Quantiacs **backtester** for avoiding **forward looking**.\n",
        "\n",
        "The backtester performs some transformations: it trains the model on one slice of data (using only data from the past) and predicts the weights for the following slice on a rolling basis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFz9Ng2FKf-M"
      },
      "outputs": [],
      "source": [
        "def train_model(data):\n",
        "    \"\"\"Create and train the model working on an asset-by-asset basis.\"\"\"\n",
        "\n",
        "    asset_name_all = data.coords[\"asset\"].values\n",
        "    target_all = get_target_classes(data)\n",
        "    features_all = get_features(data)\n",
        "\n",
        "    # Alinear ambos conjuntos de datos para garantizar consistencia\n",
        "    target_all, features_all = xr.align(target_all, features_all, join=\"inner\")\n",
        "\n",
        "    models = dict()\n",
        "\n",
        "    for asset_name in features_all.coords[\"asset\"].values:\n",
        "        if asset_name not in target_all.coords[\"asset\"].values:\n",
        "            continue  # Omitir activos que no están presentes en ambos conjuntos\n",
        "        # Drop missing values:\n",
        "        target_cur = target_all.sel(asset=asset_name).dropna(\"time\", \"any\")\n",
        "        features_cur = features_all.sel(asset=asset_name).dropna(\"time\", \"any\")\n",
        "\n",
        "        # Align features and targets:\n",
        "        target_for_learn_df, feature_for_learn_df = xr.align(target_cur, features_cur, join=\"inner\")\n",
        "\n",
        "        # Verificar si hay suficientes datos\n",
        "        if len(features_cur.time) < 10:\n",
        "            continue\n",
        "\n",
        "        # Convertir a arrays planos (1D para targets y 2D para features)\n",
        "        target_for_learn = target_for_learn_df.values.ravel()\n",
        "        features_for_learn = feature_for_learn_df.values\n",
        "\n",
        "        model = get_model()\n",
        "\n",
        "        try:\n",
        "            model.fit(features_for_learn, target_for_learn)\n",
        "            models[asset_name] = model\n",
        "\n",
        "        except Exception:\n",
        "            logging.exception(\"model training failed\")\n",
        "\n",
        "    return models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zqg_xeOwKf-M"
      },
      "outputs": [],
      "source": [
        "def predict_weights(models, data):\n",
        "    \"\"\"The model predicts if the price is going up or down.\n",
        "       The prediction is performed for several days in order to speed up the evaluation.\"\"\"\n",
        "\n",
        "    asset_name_all = data.coords[\"asset\"].values\n",
        "    weights = xr.zeros_like(data.sel(field=\"close\"))\n",
        "\n",
        "    for asset_name in asset_name_all:\n",
        "        if asset_name in models:\n",
        "            model = models[asset_name]\n",
        "            features_all = get_features(data)\n",
        "            features_cur = features_all.sel(asset=asset_name).dropna(\"time\", \"any\")\n",
        "\n",
        "            if len(features_cur.time) < 10:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Obtener probabilidades para la clase 1\n",
        "                probs = model.predict_proba(features_cur.values)[:, 1]\n",
        "                weights.loc[dict(asset=asset_name, time=features_cur.time.values)] = probs\n",
        "\n",
        "            except KeyboardInterrupt as e:\n",
        "                raise e\n",
        "\n",
        "            except Exception:\n",
        "                logging.exception(\"model prediction failed\")\n",
        "\n",
        "    return weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I71gYO0DKf-M"
      },
      "outputs": [],
      "source": [
        "# Calculate weights using the backtester:\n",
        "weights = qnbt.backtest_ml(\n",
        "    train                         = train_model,\n",
        "    predict                       = predict_weights,\n",
        "    train_period                  =  2 *365,  # the data length for training in calendar days\n",
        "    retrain_interval              = 10 *365,  # how often we have to retrain models (calendar days)\n",
        "    retrain_interval_after_submit = 1,        # how often retrain models after submission during evaluation (calendar days)\n",
        "    predict_each_day              = False,    # Is it necessary to call prediction for every day during backtesting?\n",
        "                                              # Set it to True if you suspect that get_features is looking forward.\n",
        "    competition_type              = \"stocks_s&p500\",  # competition type\n",
        "    lookback_period               = 365,                 # how many calendar days are needed by the predict function to generate the output\n",
        "    start_date                    = \"2005-01-01\",        # backtest start date\n",
        "    analyze                       = True,\n",
        "    build_plots                   = True  # do you need the chart?\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt0RIMtgKf-N"
      },
      "source": [
        "The Sharpe ratio is obviously smaller as the training process is not looking forward (as it happens by processing data on a global basis), but performed on a rolling basis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jqyjxk7rKf-N"
      },
      "source": [
        "# May I import libraries?\n",
        "\n",
        "Yes, please refer to the file **init.ipynb** in your home directory. You can for example use:\n",
        "\n",
        "! conda install -y scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq643XrSKf-N"
      },
      "source": [
        "# How to load data?\n",
        "\n",
        "Daily stock data for the **Q18 Nasdaq-100** contest can be loaded using:\n",
        "```python\n",
        "data = qndata.stocks.load_ndx_data(tail = 17*365, dims = (\"time\", \"field\", \"asset\"))\n",
        "```\n",
        "\n",
        "Cryptocurrency daily data used for the Q16/Q17 contests can be loaded using:\n",
        "```python\n",
        "data = qndata.cryptodaily.load_data(tail = 17*365, dims = (\"time\", \"field\", \"asset\"))\n",
        "```\n",
        "\n",
        "Futures data for the Q15 contest can be loaded using:\n",
        "```python\n",
        "data= qndata.futures.load_data(tail = 17*365, dims = (\"time\", \"field\", \"asset\"))\n",
        "```\n",
        "\n",
        "BTC Futures data for the Q15 contest can be loaded using:\n",
        "```python\n",
        "data= qndata.cryptofutures.load_data(tail = 17*365, dims = (\"time\", \"field\", \"asset\"))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNNmIoQxKf-N"
      },
      "source": [
        "# How to view a list of all tickers?\n",
        "\n",
        "```python\n",
        "data.asset.to_pandas().to_list()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm_3rUnjKf-N"
      },
      "source": [
        "# How to see which fields are available?\n",
        "\n",
        "```python\n",
        "data.field.to_pandas().to_list()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7ZsSZgrKf-N"
      },
      "source": [
        "# How to load specific tickers?\n",
        "\n",
        "```python\n",
        "data = qndata.stocks.load_ndx_data(tail=17 * 365, assets=[\"NAS:AAPL\", \"NAS:AMZN\"])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UBeP6fKKf-N"
      },
      "source": [
        "# How to select specific tickers after loading all data?\n",
        "\n",
        "```python\n",
        "def get_data_filter(data, assets):\n",
        "    filler= data.sel(asset=assets)\n",
        "    return filler\n",
        "\n",
        "get_data_filter(data, [\"NAS:AAPL\", \"NAS:AMZN\"])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVXP-R7DKf-N"
      },
      "source": [
        "# How to get the prices for the previous day?\n",
        "\n",
        "```python\n",
        "qnta.shift(data.sel(field=\"open\"), periods=1)\n",
        "```\n",
        "\n",
        "or:\n",
        "\n",
        "```python\n",
        "data.sel(field=\"open\").shift(time=1)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ogFfG94Kf-N"
      },
      "source": [
        "# How to get the Sharpe ratio?\n",
        "\n",
        "```python\n",
        "import qnt.stats as qnstats\n",
        "\n",
        "def get_sharpe(market_data, weights):\n",
        "    rr = qnstats.calc_relative_return(market_data, weights)\n",
        "    sharpe = qnstats.calc_sharpe_ratio_annualized(rr).values[-1]\n",
        "    return sharpe\n",
        "\n",
        "sharpe = get_sharpe(data, weights) # weights.sel(time=slice(\"2006-01-01\",None))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zCAD-VdKf-N"
      },
      "source": [
        "# How do I get a list of the top 3 assets ranked by Sharpe ratio?\n",
        "\n",
        "```python\n",
        "import qnt.stats as qnstats\n",
        "\n",
        "data = qndata.stocks.load_ndx_data(tail = 17*365, dims = (\"time\", \"field\", \"asset\"))\n",
        "\n",
        "def get_best_instruments(data, weights, top_size):\n",
        "    # compute statistics:\n",
        "    stats_per_asset = qnstats.calc_stat(data, weights, per_asset=True)\n",
        "    # calculate ranks of assets by \"sharpe_ratio\":\n",
        "    ranks = (-stats_per_asset.sel(field=\"sharpe_ratio\")).rank(\"asset\")\n",
        "    # select top assets by rank \"top_period\" days ago:\n",
        "    top_period = 1\n",
        "    rank = ranks.isel(time=-top_period)\n",
        "    top = rank.where(rank <= top_size).dropna(\"asset\").asset\n",
        "\n",
        "    # select top stats:\n",
        "    top_stats = stats_per_asset.sel(asset=top.values)\n",
        "\n",
        "    # print results:\n",
        "    print(\"SR tail of the top assets:\")\n",
        "    display(top_stats.sel(field=\"sharpe_ratio\").to_pandas().tail())\n",
        "\n",
        "    print(\"avg SR = \", top_stats[-top_period:].sel(field=\"sharpe_ratio\").mean(\"asset\")[-1].item())\n",
        "    display(top_stats)\n",
        "    return top_stats.coords[\"asset\"].values\n",
        "\n",
        "get_best_instruments(data, weights, 3)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVMM8tp9Kf-N"
      },
      "source": [
        "# How can I check the results for only the top 3 assets ranked by Sharpe ratio?\n",
        "\n",
        "Select the top assets and then load their data:\n",
        "\n",
        "```python\n",
        "best_assets= get_best_instruments(data, weights, 3)\n",
        "\n",
        "data= qndata.stocks.load_ndx_data(tail = 17*365, assets=best_assets)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sQGIRtZKf-N"
      },
      "source": [
        "# How can prices be processed?\n",
        "\n",
        "Simply import standard libraries, for example **numpy**:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "high= np.log(data.sel(field=\"high\"))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7E0hDRmKf-O"
      },
      "source": [
        "# How can you reduce slippage impace when trading?\n",
        "\n",
        "Just apply some technique to reduce turnover:\n",
        "\n",
        "```python\n",
        "def get_lower_slippage(weights, rolling_time=6):\n",
        "    return weights.rolling({\"time\": rolling_time}).max()\n",
        "\n",
        "improved_weights = get_lower_slippage(weights, rolling_time=6)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qqOUWVGKf-O"
      },
      "source": [
        "# How to use technical analysis indicators?\n",
        "\n",
        "For available indicators see the source code of the library: /qnt/ta\n",
        "\n",
        "## ATR\n",
        "\n",
        "```python\n",
        "def get_atr(data, days=14):\n",
        "    high = data.sel(field=\"high\") * 1.0\n",
        "    low  = data.sel(field=\"low\") * 1.0\n",
        "    close= data.sel(field=\"close\") * 1.0\n",
        "\n",
        "    return qnta.atr(high, low, close, days)\n",
        "\n",
        "atr= get_atr(data, days=14)\n",
        "```\n",
        "\n",
        "## EMA\n",
        "\n",
        "```python\n",
        "prices= data.sel(field=\"high\")\n",
        "prices_ema= qnta.ema(prices, 15)\n",
        "```\n",
        "\n",
        "## TRIX\n",
        "\n",
        "```python\n",
        "prices= data.sel(field=\"high\")\n",
        "prices_trix= qnta.trix(prices, 15)\n",
        "```\n",
        "\n",
        "## ADL and EMA\n",
        "\n",
        "```python\n",
        "adl= qnta.ad_line(data.sel(field=\"close\")) * 1.0\n",
        "adl_ema= qnta.ema(adl, 18)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg9bbLmyKf-O"
      },
      "source": [
        "# How can you check the quality of your strategy?\n",
        "\n",
        "```python\n",
        "import qnt.output as qnout\n",
        "qnout.check(weights, data, \"stocks_nasdaq100\")\n",
        "```\n",
        "\n",
        "or\n",
        "\n",
        "```python\n",
        "stat= qnstats.calc_stat(data, weights)\n",
        "display(stat.to_pandas().tail())\n",
        "```\n",
        "\n",
        "or\n",
        "\n",
        "```python\n",
        "import qnt.graph   as qngraph\n",
        "statistics= qnstats.calc_stat(data, weights)\n",
        "display(statistics.to_pandas().tail())\n",
        "\n",
        "performance= statistics.to_pandas()[\"equity\"]\n",
        "qngraph.make_plot_filled(performance.index, performance, name=\"PnL (Equity)\", type=\"log\")\n",
        "\n",
        "display(statistics[-1:].sel(field = [\"sharpe_ratio\"]).transpose().to_pandas())\n",
        "qnstats.print_correlation(weights, data)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUyDDg6IKf-O"
      },
      "source": [
        "# An example using pandas\n",
        "\n",
        "One can work with pandas DataFrames at intermediate steps and at the end convert them to xarray data structures:\n",
        "\n",
        "```python\n",
        "def get_price_pct_change(prices):\n",
        "    prices_pandas = prices.to_pandas()\n",
        "    assets = data.coords[\"asset\"].values\n",
        "    for asset in assets:\n",
        "        prices_pandas[asset] = prices_pandas[asset].pct_change()\n",
        "    return prices_pandas\n",
        "\n",
        "prices = data.sel(field=\"close\") * 1.0\n",
        "prices_pct_change = get_price_pct_change(prices).unstack().to_xarray()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6s5ReIiKf-O"
      },
      "source": [
        "# How to submit a strategy to the competition?\n",
        "\n",
        "Check that weights are fine:\n",
        "\n",
        "```python\n",
        "import qnt.output as qnout\n",
        "qnout.check(weights, data, \"stocks_nasdaq100\")\n",
        "```\n",
        "\n",
        "If everything is ok, write the weights to file:\n",
        "\n",
        "```python\n",
        "qnout.write(weights)\n",
        "```\n",
        "\n",
        "In your **personal account**:\n",
        "\n",
        "* **choose** a strategy;\n",
        "* click on the **Submit** button;\n",
        "* select the type of competition.\n",
        "\n",
        "At the beginning you will find the strategy under the **Checking** area:\n",
        "\n",
        "* **Sent strategies** > **Checking**.\n",
        "\n",
        "If technical checks are successful, the strategy will go under the **Candidates** area:\n",
        "\n",
        "* **Sent strategies** > **Candidates**.\n",
        "\n",
        "Otherwise it will be **Filtered**:\n",
        "\n",
        "* **Sent strategies** > **Filtered**\n",
        "\n",
        "and you should inspect error and warning messages.\n",
        "\n",
        "Note that a strategy under the **Candidates** area should have a Sharpe ratio larger than 1 for being eligible for a prize. Please check warning messages in your **Candidates** area!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}